{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luferIPCA/MIA-MLA-24-25/blob/main/2_Data_Manipulation_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kf9qddTM4D"
      },
      "source": [
        "# Masters' in Applied Artificial Intelligence\n",
        "## Machine Learning Algorithms Course MLA)\n",
        "\n",
        "Notebooks for MLA course\n",
        "\n",
        "by [*lufer*](mailto:lufer@ipca.pt)\n",
        "\n",
        "(2024)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yc6mD0jVeWN"
      },
      "source": [
        "# Part II - Datasets Manipulation (II)\n",
        "\n",
        "This is the second notebook for datasets manipulation. Cleaning, Normalizing, Initializing are some of the required tasks during dataset preparation for training.\n",
        "\n",
        "**Contents**:\n",
        "\n",
        "1. **Data Binning**\n",
        "2. **Categorical to Numerical**\n",
        "3. **Dataset Manipulation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-NymupVL02"
      },
      "source": [
        "## Environment preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Rm857IVoPe"
      },
      "source": [
        "### Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA1MzNI4TU_q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLxcgMwJEYA"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFY0ypTJJK9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# it will ask for your google drive credentiaals\n",
        "drive.mount('/content/gDrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrlsXAs4I0AZ"
      },
      "source": [
        "*Loading dataset*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/gDrive/MyDrive/Colab Notebooks/MIA - ML - 2024-2025/Datasets/\""
      ],
      "metadata": {
        "id": "qVJWEXqfw3kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(path+'credit_simple.csv', sep=';')\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "8aFyqnN_XS88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "XcW26TISXnsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c0Ddrnd8N_Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 - Data Binning\n",
        "\n",
        " Grouping technique in data analysis that enables the transformation of continuous data into discrete intervals, providing a clearer picture of the underlying trends and distributions.\n",
        "\n",
        " 1. Reduce complexity of columns values\n",
        " 2. Merging columns\n",
        " 3. Derivating columns\n",
        " 4. Reduces Noise\n",
        " 5. Facilitates Data Management:\n",
        " 6. Handling Missing Data\n",
        " 7. Eases Categorical Analysis\n",
        " 8. Enhances Data Visualization\n",
        " 9. Control Outliers\n",
        " 10. Others\n",
        "\n",
        "\n",
        " Possibe disavantges:\n",
        "\n",
        " 1. Loss of information\n",
        " 2. Inconsistency Across Different Datasets\n",
        " 3. Risk of Overfitting\n",
        " 4. Others\n",
        "\n",
        "\n",
        " See:\n",
        " * [Binning](https://medium.com/@tubelwj/pandas-data-preprocessing-data-binning-40614ab13b54)\n",
        " * [What is Data Binning](https://www.deepchecks.com/glossary/data-binning/)"
      ],
      "metadata": {
        "id": "OzD_ZHdRdXhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "rVgctxxcJEtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gLfVMEq7C3fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many categorical (objet) variables"
      ],
      "metadata": {
        "id": "MlFxaXmfxsu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the dataset, simplifying it:**\n",
        "\n",
        "* Identify the dependent variable\n",
        "* Isolate the feature \"CLASSE\""
      ],
      "metadata": {
        "id": "aucXnLqsVj0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['CLASSE']\n",
        "X = dataset.iloc[:,:-1] #all raws, all remain columns (from 0 to n-1)"
      ],
      "metadata": {
        "id": "doYiwjGRYCgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse the distribution of variable \"PROPOSITO\""
      ],
      "metadata": {
        "id": "afqp1bSoF67m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agrupado = X.groupby(['PROPOSITO']).size()\n",
        "agrupado"
      ],
      "metadata": {
        "id": "afkCQ9ECFauB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features \"Eletrodomesticos\" and \"qualificação\" are poor represented. We can move their values for other feature. For instance, move all their values to feature \"outros\"."
      ],
      "metadata": {
        "id": "fUNX9vSVGB2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[X['PROPOSITO']=='Eletrodomésticos','PROPOSITO'] = 'outros'\n",
        "#or\n",
        "#X['PROPOSITO'] = X['PROPOSITO'].replace('Eletrodomésticos', 'outros')\n",
        "X.loc[X['PROPOSITO']=='qualificação','PROPOSITO'] = 'outros'\n",
        "agrupado = X.groupby(['PROPOSITO']).size()\n",
        "agrupado"
      ],
      "metadata": {
        "id": "MhSo7XFNGB2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has now less columns!"
      ],
      "metadata": {
        "id": "0ChbDAG82K78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtypes"
      ],
      "metadata": {
        "id": "P2gNkEVk2VSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4WffXr3S8Pv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets analyse the variable \"IDADE\""
      ],
      "metadata": {
        "id": "FUImsuo03ytK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.groupby(['IDADE']).size()"
      ],
      "metadata": {
        "id": "aGtB65N_3jze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several small representations. Lets try to group values into age bins."
      ],
      "metadata": {
        "id": "eJyvQjh933Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a datafrane of all IDADE values\n",
        "sIdade = X['IDADE']\n",
        "dfIdade = pd.DataFrame(sIdade)\n",
        "dfIdade"
      ],
      "metadata": {
        "id": "FICdYajd4pwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfIdade.groupby('IDADE').size()\n"
      ],
      "metadata": {
        "id": "yn9Qp_Bk5Yhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets create coluns correspondents to bins of 10 years"
      ],
      "metadata": {
        "id": "UOnUbKjB7Xkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bins for grouping ages into periods of 10 years\n",
        "bins = range(0, 101, 10)  # 0-9, 10-19, 20-29, ..., 90-99, 100+ #array\n",
        "\n",
        "# Create a new column for the age group (bin)\n",
        "#fucntion cut() split original dataset\n",
        "dfIdade['IDADE Group'] = pd.cut(dfIdade['IDADE'], bins)\n",
        "dfIdade\n"
      ],
      "metadata": {
        "id": "M5F9u2ge79tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the new distribution\n",
        "dfIdade.groupby(['IDADE Group']).size()"
      ],
      "metadata": {
        "id": "YBMbGnRQ8c7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "j4wW5e5W4qO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IlJMObeAG0pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 - Categorical to Numeric\n"
      ],
      "metadata": {
        "id": "baxFPtntt0-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset DATA is a text object (categorical). Lets try to explore it.\n",
        "\n",
        " We can parse it to create new columns (Day, Month, etc...)\n",
        "\n",
        "1. Convert into date type\n",
        "2. Get parts of it for new columns"
      ],
      "metadata": {
        "id": "oxybTG8aGvqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['DATA']"
      ],
      "metadata": {
        "id": "RZUq62cxGB2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['DATA'] = pd.to_datetime(X['DATA'], format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "Hbh-y28hGvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['DATA']"
      ],
      "metadata": {
        "id": "AuaZPXhZGvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtypes"
      ],
      "metadata": {
        "id": "WFkocs9a2h8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create new columns ANO, MES and DIASEMANA\n",
        "X['ANO'] = X['DATA'].dt.year\n",
        "X['MES'] = X['DATA'].dt.month\n",
        "X['DIASEMANA'] = X['DATA'].dt.day_name()"
      ],
      "metadata": {
        "id": "nKoTYGdgGvqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical\n",
        "X['DIASEMANA']"
      ],
      "metadata": {
        "id": "bSvugSypGvqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.groupby(['DIASEMANA']).size()"
      ],
      "metadata": {
        "id": "LzeCCDcp2-NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "sQCFQ27P94BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have more (categorical) columns. It is relevant to understand and to convert them in Numerical."
      ],
      "metadata": {
        "id": "IRMSufWO92ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why:**\n",
        ">A structured dataset typically includes numerical and categorical variables. Machine learning algorithms can only process numerical data, not text.\n",
        "\n",
        "**Approachs:**\n",
        "\n",
        "1. Replacing categorical values\n",
        "2. Label Encoding\n",
        "3. Dummy Columns\n",
        "4. One-Hot-Encoding"
      ],
      "metadata": {
        "id": "NaHPCjw3u8WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Replacing Categorical Values\n",
        "\n",
        "**See:** section 2 on [2_Data_Manipulation_I.ipynb](https://colab.research.google.com/drive/16AMqXZnOu_e8i5EkpSG2GCGQ6EsQbPEo#scrollTo=d3iNajqoK6cA)"
      ],
      "metadata": {
        "id": "00Pvn78K-nwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Label Encoding\n",
        "\n",
        "Technique that is used to convert categorical columns into numerical ones so that they can be fitted by machine learning models.Models only take numerical data.\n",
        "\n",
        "Convert text values (categorical) in numeric\n",
        "\n",
        "**Example 1:**"
      ],
      "metadata": {
        "id": "Bl6ly9W2Q8LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['ESTADOCIVIL']"
      ],
      "metadata": {
        "id": "aCEFbAL-uG9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['ESTADOCIVIL'].unique()"
      ],
      "metadata": {
        "id": "Ci1WZt_zeXuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESTADOCIVIL has four diferent values labels. The encoding goes from 0 to 4."
      ],
      "metadata": {
        "id": "Kcjw94jDvz8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['PROPOSITO'].unique()"
      ],
      "metadata": {
        "id": "Uyh9Yc-ZetBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROPOSITO has eight diferent values labels. The encoding goes from 0 to 8."
      ],
      "metadata": {
        "id": "VyAU-Ndbv9n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['DIASEMANA'].unique()"
      ],
      "metadata": {
        "id": "utRUkROqezOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIASEMANA has seven diferent values labels. The encoding goes from 0 to 7."
      ],
      "metadata": {
        "id": "9kBgeWLHwBxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import label encoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "labelencoder1 = preprocessing.LabelEncoder()\n",
        "\n",
        "X['ESTADOCIVIL'] = labelencoder1.fit_transform(X['ESTADOCIVIL'])\n",
        "X['PROPOSITO'] = labelencoder1.fit_transform(X['PROPOSITO'])\n",
        "X['DIASEMANA'] = labelencoder1.fit_transform(X['DIASEMANA'])"
      ],
      "metadata": {
        "id": "79q7jjBYe7QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "exdZs2CbfjrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATENTION:**\n",
        "\n",
        "Label encoding converts the categorical data into numerical ones, but it assigns a unique number(starting from 0) to each class of data. This may lead to the generation of priority issues during model training of data sets. A label with a high value may be considered to have high priority than a label having a lower value."
      ],
      "metadata": {
        "id": "vtRL-T0Uw1PZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**\n"
      ],
      "metadata": {
        "id": "gTXYhKlYBBiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recover original df\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [25, 31, 25, None, 27],\n",
        "        'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "        'Country':['Portugal','Spain','England','Portugal','Germany'],\n",
        "        'Salary': [50000, None, 30000, 40000, 60000]}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Pxw5KtZOBE96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "wpLB7mxnFj-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Try to imprve the datasset: handling the NaN values)"
      ],
      "metadata": {
        "id": "P15wbQxkBc3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the data types of all columns\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "jE9HkFKNBfW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have three categorical variables (Name, Country, Gender) and two numeric (Salary, Age).\n",
        "\n",
        "Lets convert Country into a number.\n",
        "\n",
        "The possible values for Country are: Portugal, Spain, England, Germany. Thus, we can define number for each one, like\n",
        "\n",
        "* Portugal -> 2\n",
        "* Spain -> 3\n",
        "* England -> 0\n",
        "* Germany -> 1\n",
        "\n",
        "We can do it manually, but we can use transformers."
      ],
      "metadata": {
        "id": "V778UOfXCSF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import label encoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Create a label encoder object\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# Encode labels in the 'Country' column\n",
        "df['Country'] = label_encoder.fit_transform(df['Country'])\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "QMQphEoBCrpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention:**\n",
        "\n",
        "Label Encoding imposes an arbitrary order on categorical data, which can be misleading.\n",
        "\n",
        "For mitigate this, the *OneHotEncoding* approach can be used."
      ],
      "metadata": {
        "id": "PW96QQm3HdTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###One-Hot Encoding"
      ],
      "metadata": {
        "id": "ZOeZk0IGICsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* One-Hot Encoding creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature. One-Hot Encoding is the process of creating dummy variables.\n",
        "\n",
        "* It represents categorical variables as binary vectors, creating a new column for each category. Instead of assigning a single numerical label, it ensures that the encoding **does not impose** an ordinal relationship between categories.*"
      ],
      "metadata": {
        "id": "oxCXh3zkINkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:**"
      ],
      "metadata": {
        "id": "NvE2zgfHUXIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['CLASSE']\n",
        "X = dataset.iloc[:,:-1] #all raws, allcolumns from 0 to n-1\n",
        "X"
      ],
      "metadata": {
        "id": "fklG6ikxUl7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Initialize OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Apply OneHotEncoding to the 'Gender' and 'Country' columns\n",
        "columns_to_encode = ['ESTADOCIVIL']\n",
        "onehot_encoded = onehot_encoder.fit_transform(X[columns_to_encode])\n",
        "\n",
        "# Create a new DataFrame with the one-hot encoded columns\n",
        "encoded_columns = onehot_encoder.get_feature_names_out(columns_to_encode)\n",
        "encoded_df = pd.DataFrame(onehot_encoded, columns=encoded_columns)\n",
        "\n",
        "# Concatenate the original DataFrame with the new one-hot encoded columns\n",
        "newdf = pd.concat([X, encoded_df], axis=1)\n",
        "\n",
        "# Drop the original 'Gender' and 'Country' columns if no longer needed\n",
        "newdf.drop(columns=columns_to_encode, inplace=True)\n",
        "\n",
        "# Show the updated DataFrame\n",
        "newdf.head()"
      ],
      "metadata": {
        "id": "4dpy-QKKUpvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:**"
      ],
      "metadata": {
        "id": "kHA3CYinUZs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recover original df\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [25, 31, 25, None, 27],\n",
        "        'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "        'Country':['Portugal','Spain','England','Portugal','Germany'],\n",
        "        'Salary': [50000, None, 30000, 40000, 60000]}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "IQufUNvtJK1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Initialize OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Apply OneHotEncoding to the 'Gender' and 'Country' columns\n",
        "columns_to_encode = ['Gender', 'Country']\n",
        "onehot_encoded = onehot_encoder.fit_transform(df[columns_to_encode])\n",
        "\n",
        "# Create a new DataFrame with the one-hot encoded columns\n",
        "encoded_columns = onehot_encoder.get_feature_names_out(columns_to_encode)\n",
        "encoded_df = pd.DataFrame(onehot_encoded, columns=encoded_columns)\n",
        "\n",
        "# Concatenate the original DataFrame with the new one-hot encoded columns\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Drop the original 'Gender' and 'Country' columns if no longer needed\n",
        "df.drop(columns=columns_to_encode, inplace=True)\n",
        "\n",
        "# Show the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "TF42VG5-I2nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Refzvgq-JflX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy Columns\n",
        "\n",
        "Create dummy columns from the existing one using *get_dummies*"
      ],
      "metadata": {
        "id": "2M02Q2zGyn0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outros = X['OUTROSPLANOSPGTO'].unique()\n",
        "outros"
      ],
      "metadata": {
        "id": "ZrT-vufDfrnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = pd.get_dummies(X['OUTROSPLANOSPGTO'], prefix = 'OUTROS')"
      ],
      "metadata": {
        "id": "1O4iVCshf8eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "id": "b1wZ4F0EgS8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "X7XDHLk4gUTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concat both dataframes"
      ],
      "metadata": {
        "id": "CQ_FP_k-S_et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = pd.concat([X,z], axis='columns')\n",
        "newdf.head()"
      ],
      "metadata": {
        "id": "52ElooBmTDDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete original columns"
      ],
      "metadata": {
        "id": "0KXVkrvMTSeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.columns"
      ],
      "metadata": {
        "id": "TamYy5SsWUr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf=newdf.drop(['OUTROSPLANOSPGTO'], axis='columns')\n",
        "newdf.head()"
      ],
      "metadata": {
        "id": "eGW81mJgTWgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another example**"
      ],
      "metadata": {
        "id": "cCjj-hFe3acG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(filePath+'car_sales.csv', sep=';')"
      ],
      "metadata": {
        "id": "lzU8NCink_Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()\n",
        "#type(dataset)"
      ],
      "metadata": {
        "id": "HurbKaUIlI6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset (as a dictionary for this purpose)\n",
        "data = {\n",
        "    'Make': ['Toyota', 'Honda', 'Toyota', 'BMW', 'Nissan', 'Toyota', 'Honda', 'Honda', 'Toyota', ''],\n",
        "    'Colour': ['White', 'Red', 'Blue', 'Black', 'White', 'Green', '', 'Blue', 'White', 'White'],\n",
        "    'Odometer': [150043, 87899, None, 11179, 213095, None, None, None, 60000, 31600],\n",
        "    'Doors': [4, 4, 3, 5, 4, 4, 4, 4, None, 4],\n",
        "    'Price': ['$4,000', '$5,000', '$7,000', '$22,000', '$3,500', '$4,500', '$7,500', '', '', '$9,700']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create dummy columns for 'Make' using pd.get_dummies\n",
        "df_dummies = pd.get_dummies(df['Make'], prefix='Make')\n",
        "\n",
        "# Join the dummy columns back to the original dataframe\n",
        "df = pd.concat([df, df_dummies], axis=1)\n",
        "\n",
        "# Display the updated dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "f3cTCIRRnWGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#format output like a table\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "#disabling\n",
        "#data_table.disable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "6iRY9xXUM7KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pandas display options to suppress scientific notation\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "#reseting\n",
        "#pd.reset_option('display.float_format')"
      ],
      "metadata": {
        "id": "rdSc8jjlM7KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Later on next pupyte notebboks, other methods for ctegorical to numerical convertion wil ne explored"
      ],
      "metadata": {
        "id": "dxAqjo2Hxn0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 - Datasets Manipulation (more...)"
      ],
      "metadata": {
        "id": "S9kMI-QK-vlS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JsSvY0qYqrp"
      },
      "source": [
        "### Spliting Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdcwXqppEQjJ"
      },
      "source": [
        "***Slicing Data (essential)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9ZKE1u4ESOR"
      },
      "outputs": [],
      "source": [
        "a = [7, 2, 3, 7, 5, 6, 0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGZ9A6ABFpdI"
      },
      "source": [
        "the instruction *[start:stop]* includes the value in the position *start*, but not in the position *stop*. Both are optional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVd1Rj2eFfBy"
      },
      "source": [
        "Part of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azjgZAj-Y3dQ"
      },
      "outputs": [],
      "source": [
        "a[1:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2HUWWidGIU-"
      },
      "outputs": [],
      "source": [
        "a[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAFwpDLuGJg1"
      },
      "outputs": [],
      "source": [
        "a[3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj9FvhEcGT-o"
      },
      "source": [
        "Start from the end of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g9YHQ6wGTF-"
      },
      "outputs": [],
      "source": [
        "a[-4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CKBZqLtGaUK"
      },
      "outputs": [],
      "source": [
        "a[-6:-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J70NX5EdFbEp"
      },
      "source": [
        "*Values substituition*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFoLqxaxFHtK"
      },
      "outputs": [],
      "source": [
        "a[3:4] = [6, 3]\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAhStZgwGdzk"
      },
      "source": [
        "*Change the step using [start:stop:step]*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHrrDB63GfNb"
      },
      "outputs": [],
      "source": [
        "a[::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAnJHdiZHANT"
      },
      "source": [
        "*Special case: Inverting a sequence*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DEE0clpHDz4"
      },
      "outputs": [],
      "source": [
        "a[::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vIeun8V8c2Tv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVqPwIAxG63i"
      },
      "source": [
        "\n",
        "**Considering existing Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Rl8tGzIOnT"
      },
      "source": [
        "*Spliting the Dataset by Row*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nba)"
      ],
      "metadata": {
        "id": "Ww18rc5Jbfw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sDrFlb8Z53T"
      },
      "source": [
        "*Splitting  Dataframe by groups*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24W6mCVac3a"
      },
      "source": [
        "Group the data by column value *year_id*. The newly formed dataframe consists of grouped data with *year_id* = 1947."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba.info()\n"
      ],
      "metadata": {
        "id": "ux8XWfbUeCdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHqqGLGWbQsl"
      },
      "outputs": [],
      "source": [
        "# splitting dataframe by groups\n",
        "# grouping by year\n",
        "grouped = nba.groupby(nba.year_id)\n",
        "#get the group of 1947\n",
        "df_new=grouped.get_group(1947)\n",
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6jho6zxcI7f"
      },
      "outputs": [],
      "source": [
        "df_new.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6BTf5FHbqRX"
      },
      "source": [
        "*Splitting Pandas Dataframe by sized chunks*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gmA9spld7_G"
      },
      "source": [
        "Randon 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ayxlf4Rb5ef"
      },
      "outputs": [],
      "source": [
        "# splitting dataframe in a particular size\n",
        "df_split = nba.sample(frac=.6)\n",
        "df_split.reset_index()\n",
        "#df_split\n",
        "len(df_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPHP9LheAiq"
      },
      "source": [
        "Split  dataframe in different sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr8QklDpeRmJ"
      },
      "outputs": [],
      "source": [
        "#Shuffle the whole dataset first\n",
        "ds3 = nba.copy()\n",
        "ds3.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Cu8r8pek_m"
      },
      "outputs": [],
      "source": [
        "ds3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2_PnY1unfuz"
      },
      "source": [
        "Split in two dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P72JpEvek5E"
      },
      "outputs": [],
      "source": [
        "\n",
        "list_of_dataframes = np.array_split(ds3, 2)\n",
        "print(\"First:\")\n",
        "list_of_dataframes[0]\n",
        "print('-'*100)\n",
        "print(\"Second:\")\n",
        "list_of_dataframes[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpoOK0ppZAl7"
      },
      "outputs": [],
      "source": [
        "# spliting dataframe by row index\n",
        "# last 1000 rows\n",
        "df1 = nba.iloc[:1000,:]\n",
        "# first 1000 rows\n",
        "df2 = nba.iloc[1000:,:]\n",
        "print(df1)\n",
        "print(\"---------------------------\")\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwWn_8DPi1WL"
      },
      "source": [
        "*Spliting by Columns (Features)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrPAG9dyi7xr"
      },
      "outputs": [],
      "source": [
        "# Split the DataFrame using iloc[] by columns\n",
        "# first 3 columns\n",
        "df1 = nba.iloc[:,:3]\n",
        "# last 3 columns\n",
        "df2 = nba.iloc[:,3:]\n",
        "print(df1)\n",
        "print(\"---------------------------\")\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Join datasets"
      ],
      "metadata": {
        "id": "Z4vSNz0LA2--"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzZP2hFTd7-5"
      },
      "source": [
        "### Generate a new Dataset file\n",
        "After the dataset analysis it could be necessary to generate a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-3bqKBWcgGF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#print(os.getcwd())\n",
        "\n",
        "f=nba.to_csv(path+'newNBA.csv', sep=';', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei13jtNCfgk_"
      },
      "source": [
        "### Exporting only a few features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjmkDHZNfHem"
      },
      "outputs": [],
      "source": [
        "#or\n",
        "nba.to_csv(path+'newNbaII.csv',columns=['gameorder','game_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End!"
      ],
      "metadata": {
        "id": "AeB6WWkqj4-z"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}