{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luferIPCA/MIA-MLA-24-25/blob/main/9_Ensemble_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sFdu_LGitF5"
      },
      "outputs": [],
      "source": [
        "#!Begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kf9qddTM4D"
      },
      "source": [
        "# Masters' in Applied Artificial Intelligence\n",
        "## Machine Learning Algorithms Course\n",
        "\n",
        "Notebooks for the MLA course\n",
        "\n",
        "by [*lufer*](mailto:lufer@ipca.pt)\n",
        "\n",
        "(ver 2.0)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yc6mD0jVeWN"
      },
      "source": [
        "# ML Modelling - Part IX - Ensemble Machine Learning Models\n",
        "\\\n",
        "**Contents**:\n",
        "\n",
        "1.  **Ensemble Models**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explores the requirements adn processes to improve a ML model."
      ],
      "metadata": {
        "id": "iAEg0vfdoiFr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-NymupVL02"
      },
      "source": [
        "# Environment preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Rm857IVoPe"
      },
      "source": [
        "**Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA1MzNI4TU_q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "#import libraries for trainning\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Last updated: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "wuXym8xInfIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLxcgMwJEYA"
      },
      "source": [
        "**Mounting Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFY0ypTJJK9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# it will ask for your google drive credentiaals\n",
        "drive.mount('/content/gDrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Ensemble"
      ],
      "metadata": {
        "id": "2lDXlYGLEoLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ],
      "metadata": {
        "id": "LqOOL0uDgaqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read in the dataset\n",
        "filePath=\"/content/gDrive/MyDrive/Colab Notebooks/MIA - ML - 2024-2025/Datasets/\"\n",
        "df = pd.read_csv(filePath+'diabetes_data.csv')\n",
        "\n",
        "#take a look at the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Vi0dyX6wkM0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check dataset size\n",
        "df.shape"
      ],
      "metadata": {
        "id": "vXNCk55Gk5Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Data Quality"
      ],
      "metadata": {
        "id": "CPwgQYG_njsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NaN Values"
      ],
      "metadata": {
        "id": "_YzNMd7AnpAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df.notna().sum()\n",
        "#there is no null values\n",
        "#df.notna().shape"
      ],
      "metadata": {
        "id": "vpBway58nrn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "8TmF6diLnKwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "H4CrJBC5lP9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into inputs and targets\n",
        "X = df.drop(columns = ['diabetes'])\n",
        "y = df['diabetes']"
      ],
      "metadata": {
        "id": "oNMvXxWZk84b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "u6iTWVtfk-3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=df['age'],y=df['insulin'], hue=df['diabetes'])"
      ],
      "metadata": {
        "id": "ZCfnIjsArtsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalizing and Split the Data"
      ],
      "metadata": {
        "id": "yLRdcqq-s2Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "3bWtlrCllAnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Different Models"
      ],
      "metadata": {
        "id": "xrvms9NplZSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Fit a KNN Model\n",
        "\n",
        "\n",
        "The principle behind Nearest Neighbor (NN) Methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning).\n",
        "\n",
        "Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data.\n",
        "\n",
        "Supervised neighbors-based learning comes in two flavors: classification for data with discrete labels, and regression for data with continuous labels.\n",
        "\n",
        "The kNN algorithm can be considered a voting system, where the majority class label determines the class label of a new data point among its nearest ‘k’ (where k is an integer) neighbors in the feature space.\n",
        "\n",
        "In this classification problem we'll use the `KNeighborsClassifier`. It implements learning based on the  nearest neighbors of each query point, where\n",
        " is an integer value specified by the user.\n",
        "\n",
        "[See more in...](https://scikit-learn.org/stable/modules/neighbors.html#classification)"
      ],
      "metadata": {
        "id": "E5uKqgxcldHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#create new a knn model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "#create a dictionary of all values we want to test for n_neighbors\n",
        "params_knn = {'n_neighbors': np.arange(1, 25)}\n",
        "\n",
        "#use gridsearch to test all values for n_neighbors\n",
        "knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
        "\n",
        "#fit model to training data\n",
        "knn_gs.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "li93fWSxle6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#current best model\n",
        "knn_best = knn_gs.best_estimator_\n",
        "\n",
        "#check best n_neigbors value\n",
        "print(knn_gs.best_params_)"
      ],
      "metadata": {
        "id": "Q4qVZ_Ddlqiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Fit a RandomForest Model"
      ],
      "metadata": {
        "id": "r2UTkKynmYV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#create a new rf classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "#create a dictionary of all values we want to test for n_estimators\n",
        "params_rf = {'n_estimators': [50, 100, 200]}\n",
        "\n",
        "#use gridsearch to test all values for n_estimators\n",
        "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
        "\n",
        "#fit model to training data\n",
        "rf_gs.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A9ujWu06nZav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#current best model\n",
        "rf_best = rf_gs.best_estimator_\n",
        "#rf_best\n",
        "#check best n_estimators value\n",
        "print(rf_gs.best_params_)"
      ],
      "metadata": {
        "id": "PXeOa77bnaAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Fit a Logistic Regression Model"
      ],
      "metadata": {
        "id": "1sT1c45bn8CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#create a new logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "#fit the model to the training data\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OXelfBL2n_ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the three models with the test data and print their accuracy scores\n",
        "\n",
        "print('knn: {}'.format(knn_best.score(X_test, y_test)))\n",
        "print('rf: {}'.format(rf_best.score(X_test, y_test)))\n",
        "print('log_reg: {}'.format(log_reg.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "jpIfj7JsoImD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble all explored models\n",
        "\n",
        "Ensemble models requires a kind of \"voting\" process to analyse existing results of the different models."
      ],
      "metadata": {
        "id": "fbALhi9q1OHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[('knn', knn_best), ('rf', rf_best), ('log_reg', log_reg)]\n",
        "\n",
        "#in Classification: Voting mechanism\n",
        "#in Regression: Aggragation nechanism\n",
        "#create the voting classifier, finding the most frequently predicted class among all models (hard)\n",
        "ensemble = VotingClassifier(estimators, voting='hard')\n",
        "\n",
        "#fit model to training data\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "#test our model on the test data\n",
        "res=ensemble.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "fMR430O4teJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result=pd.DataFrame({\"Ensemble\":ensemble.score(X_test, y_test), \"K-NN\":knn_best.score(X_test, y_test),\"RF\":rf_best.score(X_test, y_test),\"LR\":log_reg.score(X_test, y_test)},index=[0])\n",
        "result"
      ],
      "metadata": {
        "id": "8kLJK2-DtjND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ensemble model performed better than the individual k-NN, random forest and logistic regression models!"
      ],
      "metadata": {
        "id": "hbi36Zp-7P2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Ensemble"
      ],
      "metadata": {
        "id": "kK3-qlb-E3ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore models KNN, RandonFOrest, Linear Regression"
      ],
      "metadata": {
        "id": "VC5zdp4pFG_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic regression dataset\n",
        "X, y = make_regression(n_samples=500, n_features=5, noise=0.3, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Explore KNN, RandonFOrest, Linear Regression\n",
        "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "lr_reg = LinearRegression()\n",
        "\n",
        "# Create Voting Regressor, using \"average\"\n",
        "voting_reg = VotingRegressor(estimators=[('knn', knn_reg), ('rf', rf_reg), ('lr', lr_reg)])\n",
        "\n",
        "# Train the ensemble\n",
        "voting_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = voting_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Ensemble Mean Squared Error: {mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "nhtPbgvwE7Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.std()\n"
      ],
      "metadata": {
        "id": "9IrVGwBPFo5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.var()"
      ],
      "metadata": {
        "id": "1klpn9yMFpuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(y_test, y_pred)\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "wQO6yF8kFtRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remenber:\n",
        "\n",
        "- If MSE is much smaller than y.var(), the model is performing well.\n",
        "- If MSE is much larger, the model might be underfitting."
      ],
      "metadata": {
        "id": "Xaxg0onvGfbf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6nDKkItGJ2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}