{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luferIPCA/MIA-MLA-24-25/blob/main/5_Modelling_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kf9qddTM4D"
      },
      "source": [
        "# Masters' in Applied Artificial Intelligence\n",
        "## Machine Learning Algorithms Course\n",
        "\n",
        "Notebooks for the MLA course\n",
        "\n",
        "by [*lufer*](mailto:lufer@ipca.pt)\n",
        "\n",
        "vers(2.0)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yc6mD0jVeWN"
      },
      "source": [
        "# ML Modelling - Part V-II - Classification Problems\n",
        "\\\n",
        "**Contents**:\n",
        "\n",
        "1.  **Create a Classification ML Model**\n",
        "2.  **Linear SVC Algorithm**\n",
        "3.  **Random Forest Classifier Algorithm**\n",
        "4.  **Decison Trees Algorithm**\n",
        "5.  **Logistic Regression Algoritm**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explores the creation of Machine Learning models for Classification Supervised Learning."
      ],
      "metadata": {
        "id": "iAEg0vfdoiFr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-NymupVL02"
      },
      "source": [
        "# Environment preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Rm857IVoPe"
      },
      "source": [
        "**Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA1MzNI4TU_q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#import libraries for trainning\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLxcgMwJEYA"
      },
      "source": [
        "**Mounting Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFY0ypTJJK9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# it will ask for your google drive credentiaals\n",
        "drive.mount('/content/gDrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Review of concepts"
      ],
      "metadata": {
        "id": "ReppHN2anXrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Types of ML Algorithms\n",
        "\n",
        "There is essentially four types of ML Algorithms:\n",
        "\n",
        "*   Supervised ML Algorithms\n",
        "*   Unsupervised ML Algorithms\n",
        "*   Semi-Supervised ML Algorithms\n",
        "*   Reinforcement ML Algorithms"
      ],
      "metadata": {
        "id": "I5Eep9vSntsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ML algorithms selection\n",
        "\n",
        "The selection of ML can follow the next phases:\n",
        "\n",
        "1.   **Understand Your Problem**\n",
        "\n",
        "> Understanding clearly the problem to solve. What is the goal? What is the problem all about: classification, regression, clustering, or something else? What kind of data you have to work with?\n",
        "\n",
        "2.  **(Pre-)Process the Data**\n",
        "\n",
        "> Ensure that your data is in the right format for your chosen algorithm. Process and prepare your data by Cleaning, Clustering, Regression, etc...\n",
        "\n",
        "3.  **Exploration of Data**\n",
        "\n",
        ">  Conduct data analysis to gain insights into your data. Visualizations and statistics helps you to understand the relationships within your data.\n",
        "\n",
        "4.  **Metrics Evaluation**\n",
        "\n",
        ">  Decide on the metrics that will measure the success of model. You must choose the metric that should align with your problem.\n",
        "\n",
        "5.  **Start wirh a simple model**\n",
        "\n",
        "> One should begin with the simple easy-to-learn algorithms. For classification, try regression, decision tree. Simple model provides a baseline for comparison.\n",
        "\n",
        "6.  **Use Multiple Algorithms**\n",
        "\n",
        "> Multiple algorithms allow to check that one performs better than others, in the dataset\n",
        "\n",
        "7.  **Hyperparameter Tuning**\n",
        "\n",
        "> Grid Search and Random Search can helps with adjusting parameters choose algorithm that find best combination.\n",
        "\n",
        "8.  **Cross-Validation**\n",
        "\n",
        "> Using cross-validation allow to explores the performance of your models. It is relevant to preven overfiting or underfiting.\n",
        "\n",
        "9.  **Comparing Results**\n",
        "\n",
        "> Evaluate the models’s performance by using the metrics evaluation. Compare their performance and choose that best one that align with problem’s goal.\n",
        "\n",
        "10.  **Consider Model Complexity**\n",
        "\n",
        "> Balance complexity of model and their performance. Compare their performance and choose the one that generalize better.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "see more in books:\n",
        "*   *Machine Learning*, Tom M. Mitchel\n",
        "*   *Mastering Machine Learning with Python in Six Steps*, M\n",
        "Manohar Swamynathan\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AfQmWOHOShIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Choosing a ML Algorithm"
      ],
      "metadata": {
        "id": "Ceu0N5uOmj2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a Machine Learning algortihms depend of many factors, such as the size of the datatset, the type of the data in it, the goal of the model, among other criteria."
      ],
      "metadata": {
        "id": "7jmjZq7lp3Zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sklearn offers a graphical algorithm that facilicates this selection.\n",
        "\n",
        "[go to...](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
      ],
      "metadata": {
        "id": "_X9DskdMqdnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Classification Problems\n"
      ],
      "metadata": {
        "id": "W-9uny3ilsmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider now a Supervised Learning process to deal with problems which require the given data set to be classified in two or more categories. For example, whether a person is suffering from a disease X (answer in Yes or No). A typical Classification Problem."
      ],
      "metadata": {
        "id": "-1MbdXPvoiV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\\\n",
        "Classification problems are different than regression problems primarily in their outputs. Classification problems involve categorizing data into discrete classes or labels, such as “spam” or “not spam” in email filtering models. In contrast,regression problems predict continuous, numerical outputs, like orecasting sales or temperatures."
      ],
      "metadata": {
        "id": "Yhz9QWwupiCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Dataset Preparation\n",
        "\n"
      ],
      "metadata": {
        "id": "VFv4l95wtjKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Download Dataset*\n",
        "\n",
        "This dataset is prepared for Classification Analysis\n",
        "\n",
        "\\\n",
        "see [Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)\n",
        "\n",
        "\\\n",
        "**Attribute Information:**\n",
        "\n",
        "*   `age`\n",
        "\n",
        "*   `sex`\n",
        "*   `chest pain` type (4 values)\n",
        "*   `resting blood pressure`\n",
        "*   `serum cholestoral` in mg/dl\n",
        "*   `fasting blood sugar` > 120 mg/dl\n",
        "*   `resting electrocardiographic results` (values 0,1,2)\n",
        "*   `maximum heart rate` achieved\n",
        "*   `exercise induced angina`\n",
        "*   `oldpeak` = ST depression induced by exercise relative to rest\n",
        "*   `the slope of the peak` exercise ST segment\n",
        "*   `number of major vessels` (0-3) colored by flourosopy\n",
        "*   `thal`: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
        "\n",
        "\\\n",
        "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values"
      ],
      "metadata": {
        "id": "9z_3Z0WVoiV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing a real world dataset preparaed for Regression\n",
        "\n",
        "filePath='/content/gDrive/MyDrive/Colab Notebooks/MIA - ML - 2024-2025/Datasets/'\n",
        "hd = pd.read_csv(filePath+\"heart-disease.csv\")\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "#answer: a dictionary"
      ],
      "metadata": {
        "id": "APRXNHdxoiV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hd.head(100)\n"
      ],
      "metadata": {
        "id": "lL8HmCOzyWgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to use Features to predict the target category (heart disease or not)."
      ],
      "metadata": {
        "id": "9tQNAw7noiV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(hd)\n",
        "#answer: more than 50"
      ],
      "metadata": {
        "id": "EtNCUKN0zE3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Dataset"
      ],
      "metadata": {
        "id": "hb1hcfpQzdoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pandas_profiling\n",
        "#! pip uninstall pandas-profiling\n",
        "! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
      ],
      "metadata": {
        "id": "6BZVGmz90Rcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "XY-G_poD23mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#profile = ProfileReport(hd, title=\"Heart Diseases Dataset\", html={'style' : {'full_width':True}})\n",
        "#send result to file\n",
        "#profile.to_file(output_file=filePath+\"HeartDiseasesDataset.html\")\n",
        "# analyse HeartDiseasesDataset.html\n",
        "#see https://www.geeksforgeeks.org/pandas-profiling-in-python/\n",
        "#"
      ],
      "metadata": {
        "id": "ygk2ZT5B46S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Linear SVC Algorithm\n",
        "\n",
        "\n",
        "Because we have less than 100k of raw data, let's try to explore the **Linear SVC Classification Algoritm** (see [sklearn selection ML schema](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html#)).\n",
        "\n",
        "\\\n",
        "*LinearSVC* (*Linear Support Vector Classification*)  are classes to performe binary and multi-class classification on a dataset.\n",
        "\n",
        "LinearSVC uses the linear kernel `(SVC(kernel = 'linear'))`."
      ],
      "metadata": {
        "id": "-ePtb9BQ1dGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare X and y"
      ],
      "metadata": {
        "id": "qidB2usu1gnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the Linear SVC model class\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "#setup randon seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#prepare the data for splitting: separating the target coumn from the remain columns\n",
        "X = hd.drop(\"target\", axis=1)\n",
        "y=hd[\"target\"]\n",
        "\n",
        "#split the datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)  #test=20%; train=80%\n"
      ],
      "metadata": {
        "id": "zxuyun9f10VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "lQxYBUZMrFoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y)"
      ],
      "metadata": {
        "id": "ve0t0NJCFNR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "rfhf37sHrIQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create instance of the model"
      ],
      "metadata": {
        "id": "zjEoi-hQEZVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instanciate the model\n",
        "lsvc = LinearSVC(max_iter=1000) #when not converging, explore dual=False\n",
        "\n",
        "#support vectors\n",
        "#see https://scikit-learn.org/stable/auto_examples/svm/plot_linearsvc_support_vectors.html\n"
      ],
      "metadata": {
        "id": "lfJQ77TFELxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model\n",
        "\n",
        "Once the model is created, you need to fit (or train) it. Model fitting is the process of determining the coefficients 𝑏₀, 𝑏₁, …, 𝑏ᵣ that correspond to the best value of the cost function. You fit the model with .fit():"
      ],
      "metadata": {
        "id": "QE4XDAo5LR4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fit to train datatset\n",
        "lsvc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dgvTcdmlLPgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions\n",
        "\n",
        "There is two possibilities\n",
        "\n",
        "\n",
        "*   using the `predict()` function\n",
        "*   using the `predict_proba()` function\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XooQFuI-NFK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Predicting using `predict()`***"
      ],
      "metadata": {
        "id": "T8ys-acBnPUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To simplify, apply only to the first 5 records.\n",
        "#y_predicted_rfa=model.predict(X_test[:5])\n",
        "\n",
        "#all records\n",
        "y_predicted_lsv=lsvc.predict(X_test)\n",
        "y_predicted_lsv[:5]\n",
        "#len(y_predicted_lsv)"
      ],
      "metadata": {
        "id": "4h7rsFfynPUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Predicting using `predict_proba()`***"
      ],
      "metadata": {
        "id": "EogYGQFVnsMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`predict_proba()` returns probabilities of a calssification model.\n",
        "\n",
        "* *predict_proba* returns a certainty score for the prediction. The output of predict_proba is an array with the first element being an estimate of the probability that the instance is a 0 class (or False class), and the second element being an estimate of the probability that the instance is a 1 class (or True class)\n",
        "\n",
        "* *predict_proba* ia method to predict the probability of an event using **logistic regression**.\n"
      ],
      "metadata": {
        "id": "kllG2IfmRlHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#LSVCA\n",
        "#LSVC doesn't has predict_proba()\n",
        "#y_predicted_lsv=lsvc.predict_proba(X_test) #not +posssible!\n",
        "#use CalibrateClassifierCV to calibrate the probabilites\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "clf_aux = CalibratedClassifierCV(lsvc)\n",
        "clf_aux.fit(X_train, y_train)\n",
        "\n",
        "#all records\n",
        "y_predicted_lsvca = clf_aux.predict_proba(X_test)\n",
        "\n",
        "#To simplify, only the first 5 records are explored.\n",
        "#y_predicted_lsvca=clf_aux.predict_proba(X_test[:5])\n",
        "y_predicted_lsvca[:5]"
      ],
      "metadata": {
        "id": "FtcdvVb0nsMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compare predicted probability\n",
        "#To simplify, only the first 5 records are explored.\n",
        "#dDiffP = pd.DataFrame({\"Truth\":y_test[:5], \"Probability\":y_predictedProba[:,1]})\n",
        "#all records\n",
        "dDiffP = pd.DataFrame({\"Truth\":y_test, \"Predicted\": y_predicted_lsv, \"Probability\":y_predicted_lsvca[:,1]})\n",
        "dDiffP.head()"
      ],
      "metadata": {
        "id": "L-mgEOJYnsMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluating the model\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "Evaluate the model using the *scoring method* `score()`. it  returns the mean accuracy on the given test data and labels (truth)."
      ],
      "metadata": {
        "id": "1MsyLaG0LHLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the LinearSVC (on test dataset)\n",
        "lsvc.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "zzMH-n7s3PG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare predictions to truth labels\n",
        "y_predicted = lsvc.predict(X_test)\n",
        "np.mean(y_predicted==y_test)\n",
        "#note: what that means? it is the same as score()!!!"
      ],
      "metadata": {
        "id": "yZhFoDVW50ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hd['target'].value_counts()"
      ],
      "metadata": {
        "id": "U9BTb2GG3bAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score is interesting because we only have two classes (binary classification) to predict. However can it be improved?\n",
        "\n",
        "Since we are working with test data, Let's try with \"Ensemble methods\", such as Random Forrest Algorithm."
      ],
      "metadata": {
        "id": "LLTmoL0r4d3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 - Random Forest Classifier Algorithm**\n",
        "\n",
        "The *Random Forest Classifier Algorithm* is an Ensemble method"
      ],
      "metadata": {
        "id": "04HhaUqr6i8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare, Split and Fit"
      ],
      "metadata": {
        "id": "aikW7Z7Z6MiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#set random see\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X and y data\n",
        "X = hd.drop('target', axis=1)\n",
        "y = hd['target']\n",
        "\n",
        "#Split into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "# Create a Randon Forest Classifier Model instance\n",
        "rf = RandomForestClassifier(n_estimators=100)       #by default it uses \"n_estimators=100\" decisions tress\n",
        "\n",
        "#fit the model to the train data (training the machine learning algorithm - find patterns)\n",
        "rf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "5khsQBOy4BRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse the data caarefully\n",
        "\n",
        "Let's have a new perpective from the datasets!"
      ],
      "metadata": {
        "id": "T3L5tLpJBIxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#just check if there are null values in the Train data\n",
        "X_train.isnull().sum()\n",
        "#answer: no null values"
      ],
      "metadata": {
        "id": "5BZbMEeC-OGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just check if there are null values in the test data\n",
        "X_test.isnull().sum()\n",
        "#answer: no null values"
      ],
      "metadata": {
        "id": "vDe-8YZO-cJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hd.head()"
      ],
      "metadata": {
        "id": "Bxwisect-tva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Ckeck the distribution of original target values***"
      ],
      "metadata": {
        "id": "uz725HZLCCXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import Counter\n",
        "counter = Counter(hd.target)\n",
        "\n",
        "for k,v in counter.items():\n",
        "  per = v/len(hd.target)*100\n",
        "  print(\"Class=%s Count=%d, Percentage=%.3f%%\" % (k,v,per))"
      ],
      "metadata": {
        "id": "BR5vWP_y_vHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counter.items()"
      ],
      "metadata": {
        "id": "Df0kT1Tbq-ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can we do something to improve the data? Normalizing? Stratifying?"
      ],
      "metadata": {
        "id": "FdwapJx1ByCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Graphicaly***"
      ],
      "metadata": {
        "id": "nNKaYLmDOVzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(hd.target, height=4)"
      ],
      "metadata": {
        "id": "k9AYZ5j4_byR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions"
      ],
      "metadata": {
        "id": "maUyr8zKo63x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Predicting using `predict()`***"
      ],
      "metadata": {
        "id": "bTlwpkC9J8sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To simplify, only the first 5 records are explored.\n",
        "#y_predicted_rfa=model.predict(X_test[:5])\n",
        "\n",
        "#all records\n",
        "y_predicted_rfa=rf.predict(X_test)\n",
        "y_predicted_rfa\n",
        "#len(y_predicted_lra)"
      ],
      "metadata": {
        "id": "Km2ozRmo7us0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing the truth values*"
      ],
      "metadata": {
        "id": "wIn8Ob7bKAIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "T9GipZWUOeAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comparing Truth and Predicted*"
      ],
      "metadata": {
        "id": "qI4X8HCvKUea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only the first 5 records\n",
        "#dDiff = pd.DataFrame({\"Truth\":y_test[:5], \"Predicted\":y_predicted_rfa })\n",
        "#all records\n",
        "dDiff = pd.DataFrame({\"Truth\":y_test, \"Predicted\":y_predicted_rfa })\n",
        "dDiff.head()"
      ],
      "metadata": {
        "id": "2h24CeC4CveC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Predicting using `predict_proba()`***"
      ],
      "metadata": {
        "id": "yMNLFaavye6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To simplify, only the first 5 records are explored.\n",
        "#y_predictedProba=model.predict_proba(X_test[:5])\n",
        "\n",
        "#all records\n",
        "y_predictedProba=rf.predict_proba(X_test)\n",
        "y_predictedProba[:5]\n",
        "#what this means?"
      ],
      "metadata": {
        "id": "sruh6LsmQ3nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comparing Truth and Predicted Probabilities*"
      ],
      "metadata": {
        "id": "LX9gW_zuqM0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compare predicted probability\n",
        "#To simplify, only the first 5 records are explored.\n",
        "#dDiffP = pd.DataFrame({\"Truth\":y_test[:5], \"Probability\":y_predictedProba[:,1]})\n",
        "#all records\n",
        "dDiffP = pd.DataFrame({\"Truth\":y_test, \"Probability\":y_predictedProba[:,1]})\n",
        "dDiffP.head()"
      ],
      "metadata": {
        "id": "8IDp9VnCE-9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\\\n",
        "**Comparing `predict()` with `predict_proba()`**:\n",
        "\n",
        "The first number of the array represents the probalility to be the expected label. The second, de probalility to not be!\n",
        "\n",
        "`pridict_proba()`\\\n",
        "`[0., 1.]`\n",
        "\n",
        "it means that there is 0% of probability to be \"0\". Thus it is 1;\n",
        "\n",
        "`[0.13, 0.87]`\n",
        "\n",
        "it means that there is 0.13% of probability to be \"0\" and .87% to be 1;\n",
        "\n",
        "\n",
        "\\\n",
        "**Conclusion**: the more value of second (probability) number, the more confident model is."
      ],
      "metadata": {
        "id": "n_CiuAaQUzgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "Evaluate the model using the *score method* `score()`"
      ],
      "metadata": {
        "id": "5icz6_686YMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model: check the score on the test data (use the patterns the model has learned)\n",
        "rf.score(X_test,y_test) #see accuracy_score()\n",
        "\n",
        "#answer: better Coefficient of Determination!!!"
      ],
      "metadata": {
        "id": "-TDbQnUq6XU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remarks:**\n",
        "\n",
        "1.   If we deal with structured data, use Ensemble Models. It is great to find patterns!\n",
        "2.   If we deal with unstructured data, use deep learning or transfer learning models (to be explored later).\n",
        "\n"
      ],
      "metadata": {
        "id": "mHvZju6-_ew5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at real and predicted target values"
      ],
      "metadata": {
        "id": "_ozu6F3wD4kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predicted_rfa)"
      ],
      "metadata": {
        "id": "J7LTa5Jpcyt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_test.head()\n",
        "y_predicted_rfa"
      ],
      "metadata": {
        "id": "fetHUgazOYon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*F1-score*"
      ],
      "metadata": {
        "id": "B1nDngc4EFoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print('Test Set Evaluation F1-Score=>',f1_score(y_test,y_predicted_rfa))"
      ],
      "metadata": {
        "id": "TQfvrjv5xO4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 - Decison Tree\n",
        "\n",
        "see\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "- https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html"
      ],
      "metadata": {
        "id": "J80iVbA8xhL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Data"
      ],
      "metadata": {
        "id": "S7G4cXdf2b5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#set random see\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X and y data\n",
        "X = hd.drop('target', axis=1)\n",
        "y = hd['target']\n",
        "\n",
        "#Split into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "Cvrvq0ml2ifn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "3bZTo18s573-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create instance and the model"
      ],
      "metadata": {
        "id": "UbwljwW0y1rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "#dt = DecisionTreeClassifier()\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dt.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "tIt1GygXyhFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting"
      ],
      "metadata": {
        "id": "EAwgBJahyyR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "y_pred_dt"
      ],
      "metadata": {
        "id": "a3CRoTiPyxX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating"
      ],
      "metadata": {
        "id": "1td78sGN3yST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on Training set\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred_dt))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print('F1-Score=>',f1_score(y_test,y_pred_dt))"
      ],
      "metadata": {
        "id": "05fcK8bX3zb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Worst than RandomForest?"
      ],
      "metadata": {
        "id": "CJpmg22bzhiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing RandomForest and Decision Tree Algorithms"
      ],
      "metadata": {
        "id": "PbzDKnYi0FhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_f1 = f1_score(y_test,y_predicted_rfa)\n",
        "\n",
        "dt_f1 = f1_score(y_test,y_pred_dt)\n",
        "\n",
        "rf_f1,dt_f1\n"
      ],
      "metadata": {
        "id": "8ZdtFBHw0UNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForest get better prediction!"
      ],
      "metadata": {
        "id": "DVgEhMYPyxDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dDiffP = pd.DataFrame({\"Truth\":y_test, \"Probability\":y_predictedProba[:,1]})\n",
        "dDiffP.head()"
      ],
      "metadata": {
        "id": "2ZzsKxkW7DGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Decision Tree"
      ],
      "metadata": {
        "id": "6PzDDIMk5ye8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find code for that!!!"
      ],
      "metadata": {
        "id": "qUchVMah50t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preserve the final result**"
      ],
      "metadata": {
        "id": "ohrLIg0fCwWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preserve the result\n",
        "\n",
        "dDiffP.to_csv(filePath+\"ddiffProba.csv\", index=False)"
      ],
      "metadata": {
        "id": "VrS80acRIQBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 - Logistic Regression Algoritm\n",
        "\n",
        "Despite its name, it is implemented as a linear model for classification rather than regression.\n",
        "\n",
        "* Logistic Regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (binary outcome). It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables\n",
        "\n",
        "* Logistic Regression works by using the [logistic function](https://en.wikipedia.org/wiki/Logistic_function)  to model the probability of the binary outcome as a function of the independent variables. The logistic function, also known as the sigmoid function, maps the input to a value between 0 and 1, representing the probability of the positive outcome.\n",
        "\n",
        "see more about *Logistic Regression* in:  https://realpython.com/logistic-regression-python/"
      ],
      "metadata": {
        "id": "XTgaKy_jOSG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Dataset"
      ],
      "metadata": {
        "id": "Vlb9Y5GbTmLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing a real world dataset preparaed for Regression\n",
        "\n",
        "filePath='/content/gDrive/MyDrive/MIA/ColabNotebooks/Datasets/'\n",
        "hd = pd.read_csv(filePath+\"heart-disease.csv\")\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "#answer: a dictionary"
      ],
      "metadata": {
        "id": "H9DkToDCTjfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hd.head(100)\n"
      ],
      "metadata": {
        "id": "blFfjluiTjfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare X and y"
      ],
      "metadata": {
        "id": "YvuWkusp2L_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the data for splitting\n",
        "X = hd.drop(\"target\", axis=1)\n",
        "y=hd[\"target\"]\n",
        "\n",
        "#split the datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "6ScmRAVl2L_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#using the same X_train, y_train, etc...otherwise, split again!\n",
        "\n",
        "# create a logistic regression model\n",
        "log_reg = LogisticRegression(solver='liblinear') # solver options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
        "#see https://realpython.com/logistic-regression-python/\n"
      ],
      "metadata": {
        "id": "Fb4nElgKQDjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit to data"
      ],
      "metadata": {
        "id": "nkS4reg5RYOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fRAuhzBYRbR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More details about the model"
      ],
      "metadata": {
        "id": "qaTGKfnUwOXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#more details about the model\n",
        "# array of distinct values that y takes\n",
        "model.classes_\n",
        "\n",
        "#get the value of the slope 𝑏₁\n",
        "model.coef_       # 𝑏₀ is given inside a one-dimensional array\n",
        "\n",
        "#the intercept 𝑏₀ of the linear function 𝑓\n",
        "model.intercept_  # 𝑏₁ is inside a two-dimensional array\n"
      ],
      "metadata": {
        "id": "--0jTxW9Dn4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting"
      ],
      "metadata": {
        "id": "J1zIqEYtRbiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the logistic regression model\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "p_pred=log_reg.predict_proba(X_test)\n",
        "\n",
        "#define the number format for all columns\n",
        "#see https://kiwidamien.github.io/stylish-pandas.html\n",
        "\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.DataFrame({\"Truth\": y_test, \"Predict\":y_pred, \"Predict Proba\":p_pred[:,1]}).head(5)"
      ],
      "metadata": {
        "id": "BcQFesZFRiCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "```\n",
        "\n",
        "\n",
        "*accuracy_score* returns:\n",
        "\n",
        "*   if `normalize=True` returns the fraction of correctly classified samples\n",
        "*   if `normalize=False`, returns the number of correctly classified"
      ],
      "metadata": {
        "id": "LwRrFNLtRjJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "id": "xVMkx9sVRkPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred, normalize=False)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")"
      ],
      "metadata": {
        "id": "OK5KvOgoBHr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "bcSeeNqKwlUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 - Evaluating the Classification model\n",
        "The goal is to compare the predicted with the actual values (Truth)\n",
        "\n",
        "Remember that, to evaluate the quality of the predictions, it can be used:\n",
        "\n",
        "*   Estimator score method\n",
        "*   Scoring Parameter\n",
        "*   Metric Functions\n",
        "\n",
        "\\\n",
        "see https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n"
      ],
      "metadata": {
        "id": "sT6XR6Vu3mk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Performance Metrics\n",
        "\n",
        "Classification Problems have as performance metrics:\n",
        "\n",
        "*    [Precision](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=pt-br)\n",
        "*    [Recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=pt-br)\n",
        "*    [Accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy?hl=pt-br)\n",
        "*    [F1 Score](https://en.wikipedia.org/wiki/F-score)\n",
        "*    [See more metrics in...](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
        "\n",
        "\\\n",
        "see examples in [Accuracy, Precision, Recall & F1-Score – Python Examples](https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/)"
      ],
      "metadata": {
        "id": "OScc9hra3MvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\"Accuracy\" classification score**\n",
        "\n",
        "The idea is to compare predictions  to the truth  labels.\n",
        "In previous explored algorithms (Linear SVC Algorithm, Logistic Regression Algorithm and Random Forest Classifier) we got the following accuracies:"
      ],
      "metadata": {
        "id": "wVjAU3svPP58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LSVCA\n",
        "#LSVC doesn't has predict_proba()\n",
        "#use CalibrateClassifierCV to calibrate the probabilites\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "clf = CalibratedClassifierCV(lsvc)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_predicted_lsvca = clf.predict_proba(X_test)\n",
        "\n",
        "#RFCA\n",
        "y_predicted_rfca=rf.predict_proba(X_test)\n",
        "\n",
        "#LRA\n",
        "y_predicted_lra = log_reg.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "bcqcbUgWT0N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing results with the truth values:"
      ],
      "metadata": {
        "id": "GxYJhxgnUxaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame({\"Truth\":y_test, \"Predicted_LSVC\":y_predicted_lsvca[:,1], \"Predicted_RFC\":y_predicted_rfca[:,1], \"Predicted_LR\":y_predicted_lra[:,1]})\n",
        "result.head(10)"
      ],
      "metadata": {
        "id": "SlL648ZMU8iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Scoring parameters"
      ],
      "metadata": {
        "id": "-5Ty6HUGPtEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Differents ways to calculate scores**"
      ],
      "metadata": {
        "id": "Uj-FHZcCZ4rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# it is equal to the score value (acccuracy)\n",
        "# it was used previously in tis notebook\n",
        "rf.score(X_test, y_test)\n",
        "\n",
        "#model.score(X_train, y_train)\n",
        "#what happens? Why?"
      ],
      "metadata": {
        "id": "zZxxFKnoP8wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Another way to get the same\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predicted_rfa, normalize=False)        ## normalize=False...returns quantity"
      ],
      "metadata": {
        "id": "h6Yc3SroQNa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predicted_rfa)) ## normalize=trye...returns percentages\n"
      ],
      "metadata": {
        "id": "-2kqI9aJFC8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scoring parameter** are model-evaluation tools that uses *cross-validation* (such as `model_selection.cross_val_score` and `model_selection.GridSearchCV`)"
      ],
      "metadata": {
        "id": "B64o6fn-UZzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The`cross_val_score` model evaluates a score by cross-validation, provides cross-validated accuracy scores. This model trains and tests over multiple folds of the dataset\n",
        "\n",
        "*cross_val_score* is used as a simple cross validation technique to prevent over-fitting and promote model generalisation.\n",
        "\n",
        "\\\n",
        "see more about: [cross-val-model](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)"
      ],
      "metadata": {
        "id": "C-tVczR4RV89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just to be sure, instanciate again the estimator\n",
        "#import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#set random see\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X and y data\n",
        "X = hd.drop('target', axis=1)\n",
        "y = hd['target']\n",
        "\n",
        "#Split into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "# Create a Randon Forest Classifier Model instance\n",
        "rf = RandomForestClassifier(n_estimators=100)       #by default it uses \"n_estimators=100\" decisions tress\n",
        "\n",
        "#fit the model to the train data (training the machine learning algorithm - find patterns)\n",
        "rf.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "Maok7qNsP3w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse the estimator score"
      ],
      "metadata": {
        "id": "NjxZD-vSQVBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score() returns the mean accuracy on the given test data and labels.\n",
        "rf.score(X_test,y_test)\n",
        "#return a numer"
      ],
      "metadata": {
        "id": "uJNG22KpQWnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Cross-Validation*"
      ],
      "metadata": {
        "id": "mA6e1BaiWSZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply cros_validation_score\n",
        "%%time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#cv=5  - 5 dataset folds\n",
        "\n",
        "cross_val_score(rf,X,y, cv=5)\n",
        "#returns an array"
      ],
      "metadata": {
        "id": "RQk_hIQZQZH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#more folds?\n",
        "#cross_val_score(model,X,y, cv=10)\n",
        "#what happens?"
      ],
      "metadata": {
        "id": "ThVPHP7yQzyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to select the best performance/cv numbers"
      ],
      "metadata": {
        "id": "nsOZiQfgYF84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sinlge training and test spli score\n",
        "#score() returns the mean accuracy on the given test data and labels.\n",
        "model_single_score = rf.score(X_test, y_test)\n",
        "\n",
        "#Take the mean of 5-fold cross-validation\n",
        "model_cros_val_score = np.mean(cross_val_score(rf,X,y, cv=5))\n",
        "\n",
        "#compare the two\n",
        "model_single_score,model_cros_val_score\n",
        "#waht happens?"
      ],
      "metadata": {
        "id": "nR91NZJFXd21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Heart Disiease Classifier Accuracy:{model_single_score*100:.2f}%\")"
      ],
      "metadata": {
        "id": "uV8KQPP0CeVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Heart Disease Classifier Cross-Validateed Accuracy:print(f\"MAE:{mean_absolute_error(y_test,y_preds):.2f}\")\n",
        "}%\")"
      ],
      "metadata": {
        "id": "kj2AZCFJDEOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of cross-validation model is a litle better!\n"
      ],
      "metadata": {
        "id": "MOKPRjwZZ_Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default scoring parameter of classifier  = mean accuracy\n",
        "rf.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "qR_sIn2HbHm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring parameter set no None, by default\n",
        "cross_val_score(rf,X,y, cv=5,scoring=None)"
      ],
      "metadata": {
        "id": "WTe1PUwkYiH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cross_val_score(rf,X,y, cv=5,scoring=None))"
      ],
      "metadata": {
        "id": "rA4g7w3JQeeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Scoring Parameters\n",
        "\n",
        "[see more in ](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "`scoring` parameter controls what metric is applied to the evaluated model\n",
        "\n",
        "Examples: `max_error`, `r2`,`neg_mean_absolute_error`\n",
        "\n",
        "* functions ending with *_score* return a value to maximize, the higher the better.\n",
        "\n",
        "* functions ending with *_error* or *_loss* return a value to minimize, the lower the better."
      ],
      "metadata": {
        "id": "tOoE2rn2AtLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics ROC / AUC\n",
        "\\\n",
        "**Classification model evalution Metrics**\n",
        "\n",
        "\n",
        "*   Accuracy (explored above!)\n",
        "*   Area under ROC curve\n",
        "*    Confusion Matrix\n",
        "*    Classification Report"
      ],
      "metadata": {
        "id": "dsk9Nk6UF5Ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curve**\n",
        "\n",
        "A ROC curve (*Receiver Operating Characteristic Curve*) is a graph that shows the performance of a classification model at all classification thresholds\n",
        "\n",
        "ROC curves are comparision of model's **true positive rate (tpr)** versus **false positives rate (fpr)**\n",
        "\n",
        "1.   *True positives*: model predicts 1 and truth is 1\n",
        "2.   *False positives*: model predcts 1 and truth is 0\n",
        "3.   *True negatives*: model predicts 0 and truth is 0\n",
        "4.   *False negatives*: model predicts 0 and truth is 1\n",
        "\n"
      ],
      "metadata": {
        "id": "Clql9cDQGNou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#make predictions with probabilities\n",
        "y_predict_prob = rf.predict_proba(X_test)\n",
        "y_predict_prob[:10]"
      ],
      "metadata": {
        "id": "uUfGqVxGJHt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Arrays Review"
      ],
      "metadata": {
        "id": "URJGR8fjNfFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arrays review\n",
        "len(y_predict_prob), len(y_predict_prob[0]), y_predict_prob.size, y_predict_prob.shape"
      ],
      "metadata": {
        "id": "rF21KU2IMElK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row,col=y_predict_prob.shape\n",
        "print(f\"Rows: {row}\")\n",
        "print(f\"Cols: {col}\")"
      ],
      "metadata": {
        "id": "YjI0AA6vMu5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_prob[:,0].size, y_predict_prob[:,1].size"
      ],
      "metadata": {
        "id": "NVxbfjsJLDK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v-vs6YioNiOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the positives probabilites**\n",
        "\n",
        "Positives probabilites are the second column values of `predict_proba()` array.\n",
        "\n",
        "[see more about this...](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=pt-br)"
      ],
      "metadata": {
        "id": "B31VN8DgeCbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_positives = y_predict_prob[:,1]\n",
        "#y_test.size"
      ],
      "metadata": {
        "id": "0sZO-qbcJOO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate de fpr, tpr and threshold**"
      ],
      "metadata": {
        "id": "z4cSUx1MeaKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate de fpr, tpr and Threshold\n",
        "fpr, tpr, threshold = roc_curve(y_test,y_predict_positives)"
      ],
      "metadata": {
        "id": "kg8MnXNYJk-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check fpr (False Positive Rate)*"
      ],
      "metadata": {
        "id": "uX154q3PfS9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr"
      ],
      "metadata": {
        "id": "OVHtcnw9fSxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Thresholds*\n",
        "\n",
        "The minimun thresholds means the fpr and tpr don't overlap. This is an ideal situation, and means model has an ideal measure of separability. It is perfectly able to distinguish between positive class and negative class.\n",
        "\n"
      ],
      "metadata": {
        "id": "AHCvSk9iKzGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold"
      ],
      "metadata": {
        "id": "yIad40k6eBH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpr"
      ],
      "metadata": {
        "id": "rzbHNUzIEkRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot a ROC curve**\n",
        "\n",
        "The ROC curve is plotted with *tpr* against the *fpr* where *tpr* is on the y-axis and *fpr* is on the x-axis."
      ],
      "metadata": {
        "id": "NRjIiLqeJHyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to plot a ROC curve\n",
        "import matplotlib .pyplot as plt\n",
        "\n",
        "#function receive false positve rates (fpr) and tru positive rate (tpr)\n",
        "def plot_roc_curve (fpr, trp):\n",
        "  #plot roc curve\n",
        "  plt.plot(fpr,tpr,color=\"red\", label=\"ROC\")\n",
        "  #plot a reference line wwith no predictive power\n",
        "  plt.plot([0,1],[0,1],color=\"blue\", label=\"Guessing\", linestyle=\"--\")\n",
        "\n",
        "  #customize the plot\n",
        "  plt.xlabel(\"False Positive Rate (fpr)\")\n",
        "  plt.ylabel(\"True Positive Rate (tpr)\")\n",
        "  plt.title(\"Receiver Operating Characteristic (ROC) curve\")\n",
        "  plt.legend()\n",
        "  plt.show\n",
        "\n",
        "#plot the curve\n",
        "plot_roc_curve(fpr,tpr)"
      ],
      "metadata": {
        "id": "ofeWfB8OEl8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks a perfect model! However it is now always like that. The typical ROC curce looks like:"
      ],
      "metadata": {
        "id": "Up6mNtrez_aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open('/content/gDrive/MyDrive/MIA/ColabNotebooks/Images/RocCurve.png')\n",
        "img.thumbnail((500,500))\n",
        "display(img)\n"
      ],
      "metadata": {
        "id": "D75ar2ukVbZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**AUC-ROC (Area under the curve)**\n",
        "\n",
        "ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. The Higher the AUC, the better the model is at distinguishing between patients with the disease and no disease.\n",
        "\n",
        "It is also written as **AUROC** (Area Under the Receiver Operating Characteristics)\n",
        "\n",
        "[see more about this...](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"
      ],
      "metadata": {
        "id": "U26K_SpFXRMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_test,y_predict_positives)\n",
        "#answer: a perfect model, indeed!"
      ],
      "metadata": {
        "id": "AIM4INJOVfBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "The maximun of AUC is 1...it is a perfect model."
      ],
      "metadata": {
        "id": "sY-DKSgwXwkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect ROC curve"
      ],
      "metadata": {
        "id": "wY5xCHN_wdTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a perfect ROC curve and AUC score\n",
        "fpr, tpr, tresholds = roc_curve(y_test,y_test)"
      ],
      "metadata": {
        "id": "ilm4AoX5XlB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curve(fpr,tpr)"
      ],
      "metadata": {
        "id": "AHo0qYhZYB7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect AUC"
      ],
      "metadata": {
        "id": "J8Qn4ILvwfhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perfect AUC score\n",
        "roc_auc_score(y_test,y_test)"
      ],
      "metadata": {
        "id": "AXeBUSBnYM2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "00aEMefBwqM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "Another way to evaluate a classifiction model is by using `Confusion Matrix.\n",
        "\n",
        "Confusion Matrix facilitates the comparison between the model predicted values and the expected values.\n",
        "\n",
        "[see more about...](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
      ],
      "metadata": {
        "id": "EI2tOfd9Yxvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_preds = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "3Cueujae85uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_preds)"
      ],
      "metadata": {
        "id": "-S1n5vT0A-uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Confusion Matrix Visualization*\n",
        "\n",
        "[see more about display objects](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py)\n",
        "\n",
        "\\\n",
        "**Using a pandas crosstab**"
      ],
      "metadata": {
        "id": "YX9TXnshBr3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.crosstab(y_test,y_preds)\n",
        "pd.crosstab(y_test,y_preds, rownames=[\"Actual Label\"],colnames=[\"Predicted Labels\"])"
      ],
      "metadata": {
        "id": "M6DTt7clBwGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Scikit-learning**"
      ],
      "metadata": {
        "id": "AhIkv4XuDV4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the estimator type\n",
        "#rf"
      ],
      "metadata": {
        "id": "_x_4MumHLwSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "#passing the existing confusion-matrix\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=rf.classes_)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "G0O534BABqqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#or\n",
        "#passing the estimator (all)\n",
        "ConfusionMatrixDisplay.from_estimator(estimator=rf,X=X,y=y)"
      ],
      "metadata": {
        "id": "e0Y5WVeqLCTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#or\n",
        "#Passing the predictions\n",
        "ConfusionMatrixDisplay.from_predictions(y_true=y_test,y_pred=y_preds)"
      ],
      "metadata": {
        "id": "-M3Y6SUnMXY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_test\n"
      ],
      "metadata": {
        "id": "V_pyfQ2GBqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(X_test)"
      ],
      "metadata": {
        "id": "DiXkpmc0D3Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "Sh7iEEnM0pak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_preds))"
      ],
      "metadata": {
        "id": "iCedB5j5BqkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another Representation of Classification Diagram**"
      ],
      "metadata": {
        "id": "HYavc5qcSIvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "visualizer = ClassificationReport(rf, classes=rf.classes_, support=True)\n",
        "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
        "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
        "visualizer.show()                       # Finalize and show the figure\n",
        "#see more in https://www.scikit-yb.org/en/latest/api/classifier/classification_report.html"
      ],
      "metadata": {
        "id": "V5xj7mbjRdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remember:**\n",
        "\n",
        "The metrics are defined in terms of true and false positives, and true and false negatives. Positive and negative in this case are generic names for the classes of a binary classification problem\n",
        "\n",
        "**Precision** can be seen as a measure of a classifier’s exactness. For each class, it is defined as the ratio of true positives to the sum of true and false positives. Said another way, “for all instances classified positive, what percent was correct?”\n",
        "\n",
        "**Recall** is a measure of the classifier’s completeness; the ability of a classifier to correctly find all positive instances. For each class, it is defined as the ratio of true positives to the sum of true positives and false negatives. Said another way, “for all instances that were actually positive, what percent was classified correctly?”\n",
        "\n",
        "**F1 score** is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
        "\n",
        "**Support** is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn’t change between models but instead diagnoses the evaluation process."
      ],
      "metadata": {
        "id": "0nFhsKI7SrHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision\n",
        "\n",
        "```\n",
        "# Precision Score = True Positives/ (False Positives + True Positives)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0mbOC3KJGNhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "print('Precision: %.3f' % precision_score(y_test, y_preds))"
      ],
      "metadata": {
        "id": "JmiWiRmOGPQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1-Score\n",
        "\n",
        "If you use F1 score to compare several models, **the model with the highest F1 score represents the model that is best able to classify observations into classes**.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# F1 Score is calculated as:\n",
        "\n",
        "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "where:\n",
        "\n",
        "- Precision: Correct positive predictions relative to total positive predictions\n",
        "- Recall: Correct positive predictions relative to total actual positives\n",
        "```\n",
        "\n",
        "[see more...](https://www.statology.org/f1-score-in-python/)"
      ],
      "metadata": {
        "id": "yYOKUuaWOQrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#calculate F1 score\n",
        "f1_score(y_test, y_preds)"
      ],
      "metadata": {
        "id": "Okf966gTOSsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recall | Sensitivity\n",
        "\n",
        "Recall is also known as sensitivity or the true positive rate.\n",
        "\n",
        "\n",
        "```\n",
        "# Recall Score = True Positives / (False Negatives + True Positives)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7EKrXUbQFdMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "print('Recall: %.3f' % recall_score(y_test, y_preds))"
      ],
      "metadata": {
        "id": "USWhggEzR2Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Rate\n",
        "\n",
        "The error rate is the opposite of accuracy, which is the proportion of incorrect predictions. Error rate tells you how often your model makes a mistake, regardless of the label\n",
        "\n",
        "\n",
        "<div><img src=\"https://classeval.files.wordpress.com/2015/06/error-rate.png?w=880\" width=\"50%\">\n",
        "</img>\n",
        "\n",
        "(https://classeval.files.wordpress.com/2015/06/error-rate.png?w=880\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-bB_fHRKgF1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "accuracy = accuracy_score(y_test, y_preds)\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "id": "KsPYFWdhyHHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "error_rate = 1 - accuracy\n",
        "error_rate\n",
        "print(f\"Error Rate:{(error_rate):.3f}%\")\n"
      ],
      "metadata": {
        "id": "ADsDVNim_hTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy and Precision Dilema\n",
        "\n",
        "**A great accuracy does mot necessarily means success!**"
      ],
      "metadata": {
        "id": "G70WfiPREvDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets analyse the folowing controverse  example"
      ],
      "metadata": {
        "id": "UNWBiyKZE0BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#when precision and recall  become valuable\n",
        "\n",
        "disease_good= np.zeros(10000)    #array of 10000 zeros\n",
        "#disease_good\n",
        "#supose only one value of the array is 1\n",
        "disease_good[0]=1               #only one positive case\n",
        "\n",
        "#supose predictions\n",
        "disease_preds=np.zeros(10000)    #model predicts every case as 0\n",
        "\n",
        "#pd.set_option(\"display.precision\", 2)\n",
        "print(classification_report(disease_preds,\n",
        "                            disease_good,\n",
        "                            target_names=[\"Zero (0)\",\"One (1)\"],\n",
        "                            digits=2))\n"
      ],
      "metadata": {
        "id": "5JBuVDDeE_o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(classification_report(disease_good,disease_preds,output_dict=True))"
      ],
      "metadata": {
        "id": "VU78l_fzGwFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Another Example*"
      ],
      "metadata": {
        "id": "cXdqXbD5NDMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = [0, 0, 0, 0, 0, 0, 0]\n",
        "y_pred = [1, 0, 0, 0, 0, 0, 0]\n",
        "target_names = ['class 0', 'class 1']\n",
        "\n",
        "#print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "pd.DataFrame(classification_report(y_true, y_pred, target_names=target_names,output_dict=True))\n"
      ],
      "metadata": {
        "id": "KT8ChDdTJhH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "paTwpTzrGnmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Example: Diabetes"
      ],
      "metadata": {
        "id": "VrOsbqxk5jxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cZWr_4KcxnQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing a real world dataset prepared for Classifcation\n",
        "\n",
        "filePath='/content/gDrive/MyDrive/MIA/ColabNotebooks/Datasets/'\n",
        "data= pd.read_csv(filePath+\"pima-indians-diabetes.csv\")\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "#answer: a dictionary"
      ],
      "metadata": {
        "id": "0WLOohQtr5RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "npBtuGNksC1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Define column names"
      ],
      "metadata": {
        "id": "iav2cHzutqWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(index=str, columns={\"6\":\"preg\"})\n",
        "data = data.rename(index=str, columns={\"148\":\"gluco\"})\n",
        "data = data.rename(index=str, columns={\"72\":\"bp\"})\n",
        "data = data.rename(index=str, columns={\"35\":\"stinmm\"})\n",
        "data = data.rename(index=str, columns={\"0\":\"insulin\"})\n",
        "data = data.rename(index=str, columns={\"33.6\":\"mass\"})\n",
        "data =data.rename(index=str, columns={\"0.627\":\"dpf\"})\n",
        "data = data.rename(index=str, columns={\"50\":\"age\"})\n",
        "data = data.rename(index=str, columns={\"1\":\"target\"})"
      ],
      "metadata": {
        "id": "EUWdPvgssUiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "YHcHCsIwscW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Null Values"
      ],
      "metadata": {
        "id": "vmTE_tOQsk9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#len(data)\n",
        "#number of nulls, by column\n",
        "data.isnull().sum()\n",
        "#columns name with nulls\n",
        "#data.columns[data.isnull().any()]\n",
        "#answer: no null values"
      ],
      "metadata": {
        "id": "rl4HTzfZskN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the Dataset"
      ],
      "metadata": {
        "id": "HUusk6Pss7px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#divide dataset\n",
        "\n",
        "#import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Accuracy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#set random see\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X and y data\n",
        "Xd = data.drop('target', axis=1)\n",
        "yd = data['target']\n",
        "\n",
        "#Split into Train and Test\n",
        "Xd_train, Xd_test, yd_train, yd_test = train_test_split(Xd,yd,test_size=0.2)\n",
        "\n",
        "# Create a Randon Forest Classifier Model instance\n",
        "model = RandomForestClassifier(n_estimators=100)       #by default it uses \"n_estimators=100\" decisions tress\n",
        "\n",
        "#fit the model to the train data (training the machine learning algorithm - find patterns)\n",
        "model.fit(Xd_train,yd_train)"
      ],
      "metadata": {
        "id": "-C8EvATNs67U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Xd_test), len(Xd_train), len(Xd)"
      ],
      "metadata": {
        "id": "VtPZeCyIJ6YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yd_test.size"
      ],
      "metadata": {
        "id": "mBbwCLqeKkCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ckeck accuracy"
      ],
      "metadata": {
        "id": "mzJAe_iNtELO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score() returns the mean accuracy on the given test data and labels.\n",
        "model.score(Xd_test,yd_test)\n",
        "#return a number"
      ],
      "metadata": {
        "id": "dIjF2w5itGjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#make predictions with probabilities\n",
        "yd_predict_prob = model.predict_proba(Xd_test)\n",
        "yd_predict_prob[:10]"
      ],
      "metadata": {
        "id": "j__JDjpptnkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yd_predict_prob.shape"
      ],
      "metadata": {
        "id": "vsyMPLLPKu4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the positives probabilites**\n",
        "\n",
        "Positives probabilites are the second column values of `predict_proba()` array.\n",
        "\n",
        "[see more about this...](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=pt-br)"
      ],
      "metadata": {
        "id": "ryuyb2uLtnkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yd_predict_positives = yd_predict_prob[:,1]\n",
        "#first 10\n",
        "y_predict_positives[:10]"
      ],
      "metadata": {
        "id": "UW-vyEVmtnkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(yd_test)"
      ],
      "metadata": {
        "id": "9ShNhkiNJlQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(yd_predict_positives)\n",
        "#yd_predict_positives.shape"
      ],
      "metadata": {
        "id": "Dzmi2NkvJqXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate de fpr, tpr and threshold**"
      ],
      "metadata": {
        "id": "1QQ73oB6tnkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate de fpr, tpr and Threshold\n",
        "fpr, tpr, threshold = roc_curve(yd_test,yd_predict_positives)\n",
        "#check the rates\n",
        "#fpr\n",
        "#tpr\n",
        "#threshold"
      ],
      "metadata": {
        "id": "lL9FxB1TtnkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the ROC curve\n"
      ],
      "metadata": {
        "id": "UHucZI1YtnkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to plot a ROC curve\n",
        "import matplotlib .pyplot as plt\n",
        "\n",
        "#function receive false positve rates (fpr) and tru positive rate (tpr)\n",
        "def plot_roc_curve (fpr, trp):\n",
        "  #plot roc curve\n",
        "  plt.plot(fpr,tpr,color=\"red\", label=\"ROC\")\n",
        "  #plot a reference line wwith no predictive power\n",
        "  #plt.plot([0,1],[0,1],color=\"blue\", label=\"Guessing\", linestyle=\"--\")\n",
        "\n",
        "  #customize the plot\n",
        "  plt.xlabel(\"False Positive Rate (fpr)\")\n",
        "  plt.ylabel(\"True Positive Rate (tpr)\")\n",
        "  plt.title(\"Receiver Operating Characteristic (ROC) curve\")\n",
        "  plt.legend()\n",
        "  plt.show\n",
        "\n",
        "#plot the curve\n",
        "plot_roc_curve(fpr,tpr)"
      ],
      "metadata": {
        "id": "hBLkJ7rmtnkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "AUC-ROC (Area under the curve)\n"
      ],
      "metadata": {
        "id": "FGfUhcUeu3KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(yd_test,yd_predict_positives)"
      ],
      "metadata": {
        "id": "ehmbCXfJu3KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot ROC curve using sklearn*\n",
        "\n",
        "[see](https://scikit-learn.org/stable/visualizations.html#visualizations)"
      ],
      "metadata": {
        "id": "kjk8UFA-EXQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "rfc_disp = RocCurveDisplay.from_estimator(model, Xd_test, yd_test)"
      ],
      "metadata": {
        "id": "ze5sVWnNEbBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explore Support Vector Classification Algotihm**\n",
        "\n",
        "For large datasets consider using `LinearSVC`!!!"
      ],
      "metadata": {
        "id": "ngCB431RGj_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(Xd_train, yd_train)"
      ],
      "metadata": {
        "id": "qSsF1_wxF4ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc.score(Xd_test,yd_test), model.score(Xd_test,yd_test)"
      ],
      "metadata": {
        "id": "pETHgQ9jH7bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comparing graphically both results*"
      ],
      "metadata": {
        "id": "UxLCuMkXH4Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The plt.gca() function gets the current axes so that you can draw on it directly\n",
        "ax = plt.gca()\n",
        "svc_disp = RocCurveDisplay.from_estimator(svc, Xd_test, yd_test, ax=ax, alpha=0.8)\n",
        "rfc_disp.plot(ax=ax, alpha=0.8)"
      ],
      "metadata": {
        "id": "OxaQONlQHu5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Classification Models: summary\n",
        "\n",
        "Lets apply all explored metrics briefly:"
      ],
      "metadata": {
        "id": "v3CdGZCxUmiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- Load datatset\n",
        "\n",
        "Data must be prepareed for classification (ex. Heart Disiease)"
      ],
      "metadata": {
        "id": "wgS8xFHGVRFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing a real world dataset preparaed for Regression\n",
        "\n",
        "filePath='/content/gDrive/MyDrive/MIA/ColabNotebooks/Datasets/'\n",
        "hd = pd.read_csv(filePath+\"heart-disease.csv\")\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "#answer: a dictionary"
      ],
      "metadata": {
        "id": "_Q-6MQZHVcqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Create Model"
      ],
      "metadata": {
        "id": "oxXbwNSdVSpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the environment\n",
        "#import metris\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "#import model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Create X and y\n",
        "X=hd.drop(\"target\",axis=1)\n",
        "y = hd['target']\n",
        "\n",
        "#Split data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=42) # experiment with  stratify=y)\n",
        "\n",
        "#Create model\n",
        "\n",
        "model=RandomForestClassifier()  #n_estimators=100\n",
        "\n",
        "#Fit model (features/labels)\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_preds= model.predict(X_test)"
      ],
      "metadata": {
        "id": "y3pxTdpgUmHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Evaluate"
      ],
      "metadata": {
        "id": "W2qPnh-WVXWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model using sklearn functions\n",
        "print(\"Classification Metrics\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test,y_preds)}\")\n",
        "print(f\"Precision:{precision_score(y_test,y_preds)}\")\n",
        "print(f\"Recall: {recall_score(y_test,y_preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_test,y_preds)}\")\n"
      ],
      "metadata": {
        "id": "9QZVenBCZux2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#End!"
      ],
      "metadata": {
        "id": "QjQdyenSYfpv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}